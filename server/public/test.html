<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>VAPI å®æ—¶è¯­éŸ³æµ‹è¯•</title>
  <style>
    * { box-sizing: border-box; }
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      max-width: 900px;
      margin: 0 auto;
      padding: 20px;
      background: #f5f5f5;
    }
    h1 { margin: 0 0 20px; font-size: 24px; }
    
    .status-bar {
      display: flex;
      align-items: center;
      gap: 12px;
      padding: 12px 16px;
      background: white;
      border-radius: 12px;
      margin-bottom: 20px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.08);
    }
    .status-dot {
      width: 12px;
      height: 12px;
      border-radius: 50%;
      background: #ccc;
      transition: background 0.3s;
    }
    .status-dot.connected { background: #4CAF50; }
    .status-dot.speaking { background: #FF9800; animation: pulse 1s infinite; }
    .status-dot.thinking { background: #2196F3; animation: pulse 0.5s infinite; }
    @keyframes pulse {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.5; }
    }
    
    .main-area {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 20px;
    }
    
    .panel {
      background: white;
      border-radius: 12px;
      padding: 16px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.08);
    }
    .panel h3 {
      margin: 0 0 12px;
      font-size: 14px;
      color: #666;
      text-transform: uppercase;
      letter-spacing: 0.5px;
    }
    
    .controls {
      display: flex;
      flex-direction: column;
      gap: 12px;
    }
    
    button {
      padding: 12px 20px;
      border: none;
      border-radius: 8px;
      cursor: pointer;
      font-size: 14px;
      font-weight: 500;
      transition: all 0.2s;
    }
    button:disabled {
      opacity: 0.5;
      cursor: not-allowed;
    }
    .btn-primary {
      background: #2196F3;
      color: white;
    }
    .btn-primary:hover:not(:disabled) {
      background: #1976D2;
    }
    .btn-danger {
      background: #f44336;
      color: white;
    }
    .btn-danger:hover:not(:disabled) {
      background: #d32f2f;
    }
    .btn-success {
      background: #4CAF50;
      color: white;
    }
    .btn-success:hover:not(:disabled) {
      background: #388E3C;
    }
    
    .record-btn {
      width: 80px;
      height: 80px;
      border-radius: 50%;
      background: #f44336;
      color: white;
      font-size: 24px;
      align-self: center;
      border: 4px solid #ffcdd2;
    }
    .record-btn.recording {
      background: #d32f2f;
      border-color: #ef5350;
      animation: pulse 1s infinite;
    }
    
    .chat-log {
      height: 400px;
      overflow-y: auto;
      font-family: monospace;
      font-size: 13px;
      background: #1e1e1e;
      color: #0f0;
      padding: 12px;
      border-radius: 8px;
    }
    .log-entry { margin-bottom: 4px; }
    .log-time { color: #666; }
    .log-sent { color: #ff0; }
    .log-received { color: #0ff; }
    .log-error { color: #f44336; }
    .log-ai { color: #4CAF50; }
    
    .text-input-area {
      display: flex;
      gap: 8px;
      margin-top: 12px;
    }
    .text-input-area input {
      flex: 1;
      padding: 10px 12px;
      border: 1px solid #ddd;
      border-radius: 8px;
      font-size: 14px;
    }
    .text-input-area input:focus {
      outline: none;
      border-color: #2196F3;
    }
    
    .transcript {
      margin-top: 12px;
      padding: 12px;
      background: #f5f5f5;
      border-radius: 8px;
      min-height: 60px;
      font-size: 14px;
    }
    .transcript-empty {
      color: #999;
      font-style: italic;
    }
    
    .audio-indicator {
      font-size: 12px;
      color: #666;
      text-align: center;
      margin-top: 4px;
    }
    
    @media (max-width: 700px) {
      .main-area {
        grid-template-columns: 1fr;
      }
    }
  </style>
</head>
<body>
  <h1>ğŸ¤ VAPI å®æ—¶è¯­éŸ³æµ‹è¯•</h1>
  
  <div class="status-bar">
    <div class="status-dot" id="statusDot"></div>
    <span id="statusText">æœªè¿æ¥</span>
  </div>
  
  <div class="main-area">
    <div class="panel">
      <h3>æ§åˆ¶é¢æ¿</h3>
      <div class="controls">
        <button id="connectBtn" class="btn-primary" onclick="toggleConnect()">è¿æ¥æœåŠ¡å™¨</button>
        
        <button class="record-btn" id="recordBtn" onclick="toggleRecord()" disabled>
          ğŸ™ï¸
        </button>
        <p class="audio-indicator" id="audioIndicator">ç‚¹å‡»å½•éŸ³ï¼ˆéœ€è¦å…ˆè¿æ¥ï¼‰</p>
        
        <div class="text-input-area">
          <input type="text" id="textInput" placeholder="è¾“å…¥æ–‡æœ¬æ¶ˆæ¯..." onkeypress="if(event.key==='Enter')sendText()" disabled>
          <button class="btn-primary" onclick="sendText()" id="sendBtn" disabled>å‘é€</button>
        </div>
      </div>
      
      <div class="transcript">
        <div id="transcriptText" class="transcript-empty">å¯¹è¯å†…å®¹å°†æ˜¾ç¤ºåœ¨è¿™é‡Œ...</div>
      </div>
    </div>
    
    <div class="panel">
      <h3>æ—¥å¿—</h3>
      <div class="chat-log" id="log"></div>
      <button onclick="clearLog()" style="margin-top: 8px; padding: 8px 12px; font-size: 12px;">æ¸…ç©ºæ—¥å¿—</button>
    </div>
  </div>
  
  <script>
    let ws = null;
    let mediaRecorder = null;
    let audioContext = null;
    let audioQueue = [];
    let isPlaying = false;
    let currentAudioSource = null;
    let currentTranscript = '';
    let isRecording = false;
    let audioStream = null;
    let reconnectAttempts = 0;
    const MAX_RECONNECT = 5;
    
    const statusDot = document.getElementById('statusDot');
    const statusText = document.getElementById('statusText');
    const recordBtn = document.getElementById('recordBtn');
    const textInput = document.getElementById('textInput');
    const sendBtn = document.getElementById('sendBtn');
    const connectBtn = document.getElementById('connectBtn');
    const transcriptText = document.getElementById('transcriptText');
    const audioIndicator = document.getElementById('audioIndicator');
    
    function log(msg, type = 'info') {
      const logDiv = document.getElementById('log');
      const time = new Date().toLocaleTimeString();
      const cls = type === 'ai' ? 'log-ai' : (type === 'sent' ? 'log-sent' : (type === 'received' ? 'log-received' : (type === 'error' ? 'log-error' : '')));
      logDiv.innerHTML += `<div class="log-entry ${cls}"><span class="log-time">[${time}]</span> ${msg}</div>`;
      logDiv.scrollTop = logDiv.scrollHeight;
    }
    
    function clearLog() {
      document.getElementById('log').innerHTML = '';
    }
    
    function updateStatus(status, text) {
      statusDot.className = 'status-dot ' + status;
      statusText.textContent = text;
    }
    
    function toggleConnect() {
      if (ws && ws.readyState === WebSocket.OPEN) {
        ws.close();
        return;
      }
      
      connectWebSocket();
    }
    
    function connectWebSocket() {
      const url = 'ws://localhost:3000/ws/conversations/' + Date.now() + '?assistant_id=default';
      log(`æ­£åœ¨è¿æ¥: ${url}`, 'sent');
      
      ws = new WebSocket(url);
      
      ws.onopen = () => {
        log('âœ… WebSocket å·²è¿æ¥', 'received');
        updateStatus('connected', 'å·²è¿æ¥');
        connectBtn.textContent = 'æ–­å¼€è¿æ¥';
        connectBtn.className = 'btn-danger';
        recordBtn.disabled = false;
        textInput.disabled = false;
        sendBtn.disabled = false;
        reconnectAttempts = 0;
      };
      
      ws.onmessage = async (event) => {
        try {
          const data = JSON.parse(event.data);
          handleMessage(data);
        } catch (e) {
          log(`ğŸ“¥ ${event.data}`, 'received');
        }
      };
      
      ws.onerror = (error) => {
        log('âŒ WebSocket é”™è¯¯', 'error');
        updateStatus('', 'è¿æ¥é”™è¯¯');
      };
      
      ws.onclose = (event) => {
        log(`ğŸ”Œ WebSocket å·²æ–­å¼€ (code: ${event.code})`, 'info');
        updateStatus('', 'æœªè¿æ¥');
        connectBtn.textContent = 'è¿æ¥æœåŠ¡å™¨';
        connectBtn.className = 'btn-primary';
        recordBtn.disabled = true;
        textInput.disabled = true;
        sendBtn.disabled = true;
        stopRecording();
        
        // è‡ªåŠ¨é‡è¿ï¼ˆéä¸»åŠ¨å…³é—­ï¼‰
        if (event.code !== 1000 && reconnectAttempts < MAX_RECONNECT) {
          reconnectAttempts++;
          log(`ğŸ”„ ${3}ç§’åé‡è¿ (${reconnectAttempts}/${MAX_RECONNECT})...`, 'info');
          setTimeout(connectWebSocket, 3000);
        }
      };
    }
    
    function handleMessage(data) {
      switch (data.type) {
        case 'welcome':
          log(`ğŸ‘‹ ${data.data.message}`, 'received');
          break;
          
        case 'transcription':
          const text = data.data.text;
          const role = data.data.role;
          log(`${role === 'user' ? 'ğŸ‘¤ ç”¨æˆ·' : 'ğŸ¤– AI'}: ${text}`, role === 'user' ? 'sent' : 'ai');
          updateTranscript(role, text);
          
          // ç”¨æˆ·è¯´è¯æ—¶ï¼Œåœæ­¢ AI æ’­æ”¾ï¼ˆæ‰“æ–­æœºåˆ¶ï¼‰
          if (role === 'user' && isPlaying) {
            stopAudioPlayback();
            log('â¸ï¸ AI è¢«æ‰“æ–­', 'info');
          }
          break;
          
        case 'text_delta':
          // æµå¼æ–‡æœ¬å¯ä»¥åœ¨è¿™é‡Œåšæ‰“å­—æœºæ•ˆæœ
          break;
          
        case 'audio':
          if (data.data.audio) {
            queueAudio(data.data.audio, data.data.sample_rate || 24000);
          }
          break;
          
        case 'status':
          const status = data.data.status;
          const message = data.data.message;
          if (status === 'thinking') {
            updateStatus('thinking', message);
          } else if (status === 'ai_speaking') {
            updateStatus('speaking', message);
            audioIndicator.textContent = 'ğŸ”Š AI æ­£åœ¨è¯´è¯...';
          } else if (status === 'connected' || status === 'ai_done') {
            updateStatus('connected', message || 'å°±ç»ª');
            audioIndicator.textContent = 'ç‚¹å‡»å½•éŸ³';
          } else {
            log(`ğŸ“Š ${message}`, 'received');
          }
          break;
          
        case 'error':
          log(`âŒ é”™è¯¯: ${data.data.error}`, 'error');
          updateStatus('', 'é”™è¯¯');
          break;
          
        case 'interrupted':
          log('â¸ï¸ è¢«ç”¨æˆ·æ‰“æ–­', 'info');
          stopAudioPlayback();
          break;
          
        default:
          log(`ğŸ“¥ ${data.type}`, 'received');
      }
    }
    
    function updateTranscript(role, text) {
      const speaker = role === 'user' ? 'ğŸ‘¤' : 'ğŸ¤–';
      currentTranscript += `${speaker} ${text}\n`;
      transcriptText.textContent = currentTranscript;
      transcriptText.classList.remove('transcript-empty');
    }
    
    // ===== éŸ³é¢‘æ’­æ”¾é˜Ÿåˆ— =====
    
    function queueAudio(base64Audio, sampleRate) {
      audioQueue.push({ base64Audio, sampleRate });
      if (!isPlaying) {
        playNextAudio();
      }
    }
    
    async function playNextAudio() {
      if (audioQueue.length === 0) {
        isPlaying = false;
        audioIndicator.textContent = 'ç‚¹å‡»å½•éŸ³';
        return;
      }
      
      isPlaying = true;
      const { base64Audio, sampleRate } = audioQueue.shift();
      
      try {
        if (!audioContext || audioContext.state === 'closed') {
          audioContext = new (window.AudioContext || window.webkitAudioContext)();
        }
        
        // è§£ç  base64
        const binary = atob(base64Audio);
        const bytes = new Uint8Array(binary.length);
        for (let i = 0; i < binary.length; i++) {
          bytes[i] = binary.charCodeAt(i);
        }
        
        // PCM16 -> Float32
        const int16 = new Int16Array(bytes.buffer);
        const float32 = new Float32Array(int16.length);
        for (let i = 0; i < int16.length; i++) {
          float32[i] = int16[i] / 32768.0;
        }
        
        // åˆ›å»º AudioBuffer
        const audioBuffer = audioContext.createBuffer(1, float32.length, sampleRate);
        audioBuffer.getChannelData(0).set(float32);
        
        // æ’­æ”¾
        currentAudioSource = audioContext.createBufferSource();
        currentAudioSource.buffer = audioBuffer;
        currentAudioSource.connect(audioContext.destination);
        
        currentAudioSource.onended = () => {
          currentAudioSource = null;
          playNextAudio(); // æ’­æ”¾ä¸‹ä¸€ä¸ª
        };
        
        currentAudioSource.start();
        
      } catch (e) {
        console.error('éŸ³é¢‘æ’­æ”¾é”™è¯¯:', e);
        log(`âŒ éŸ³é¢‘æ’­æ”¾é”™è¯¯: ${e.message}`, 'error');
        playNextAudio(); // ç»§ç»­ä¸‹ä¸€ä¸ª
      }
    }
    
    function stopAudioPlayback() {
      if (currentAudioSource) {
        try {
          currentAudioSource.stop();
        } catch (e) {}
        currentAudioSource = null;
      }
      audioQueue = []; // æ¸…ç©ºé˜Ÿåˆ—
      isPlaying = false;
      audioIndicator.textContent = 'ç‚¹å‡»å½•éŸ³';
    }
    
    // ===== å½•éŸ³ =====
    
    async function toggleRecord() {
      if (isRecording) {
        stopRecording();
      } else {
        await startRecording();
      }
    }
    
    async function startRecording() {
      try {
        // åœæ­¢ AI æ’­æ”¾
        stopAudioPlayback();
        
        audioStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            sampleRate: 16000,
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true
          }
        });
        
        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
        const source = audioContext.createMediaStreamSource(audioStream);
        const processor = audioContext.createScriptProcessor(4096, 1, 1);
        
        source.connect(processor);
        processor.connect(audioContext.destination);
        
        processor.onaudioprocess = (e) => {
          if (isRecording && ws && ws.readyState === WebSocket.OPEN) {
            const inputData = e.inputBuffer.getChannelData(0);
            // Float32 -> Int16 (PCM16)
            const pcm16 = new Int16Array(inputData.length);
            for (let i = 0; i < inputData.length; i++) {
              const s = Math.max(-1, Math.min(1, inputData[i]));
              pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            ws.send(pcm16.buffer);
          }
        };
        
        isRecording = true;
        recordBtn.classList.add('recording');
        recordBtn.textContent = 'â¹ï¸';
        updateStatus('speaking', 'æ­£åœ¨å½•éŸ³...');
        audioIndicator.textContent = 'ğŸ”´ å½•éŸ³ä¸­...ç‚¹å‡»åœæ­¢';
        log('ğŸ¤ å¼€å§‹å½•éŸ³', 'sent');
        
        window.currentProcessor = processor;
        
      } catch (e) {
        log(`âŒ æ— æ³•è®¿é—®éº¦å…‹é£: ${e.message}`, 'error');
      }
    }
    
    function stopRecording() {
      if (audioStream) {
        audioStream.getTracks().forEach(track => track.stop());
        audioStream = null;
      }
      if (window.currentProcessor) {
        window.currentProcessor.disconnect();
        window.currentProcessor = null;
      }
      
      isRecording = false;
      recordBtn.classList.remove('recording');
      recordBtn.textContent = 'ğŸ™ï¸';
      updateStatus('connected', 'å°±ç»ª');
      audioIndicator.textContent = 'ç‚¹å‡»å½•éŸ³';
      
      if (ws && ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({ type: 'control', data: { command: 'commit' } }));
        log('â¹ï¸ åœæ­¢å½•éŸ³ï¼Œå·²æäº¤', 'sent');
      }
    }
    
    function sendText() {
      const text = textInput.value.trim();
      if (!text) return;
      if (!ws || ws.readyState !== WebSocket.OPEN) {
        log('âŒ æœªè¿æ¥', 'error');
        return;
      }
      
      // åœæ­¢ AI æ’­æ”¾
      stopAudioPlayback();
      
      const message = {
        type: 'text',
        data: { content: text }
      };
      
      ws.send(JSON.stringify(message));
      log(`ğŸ“¤ å‘é€: ${text}`, 'sent');
      textInput.value = '';
    }
  </script>
</body>
</html>
